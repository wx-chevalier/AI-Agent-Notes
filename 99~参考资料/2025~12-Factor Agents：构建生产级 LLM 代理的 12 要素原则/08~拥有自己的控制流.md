# 拥有自己的控制流

尽管 LLM 具备"推理"能力，但应用的整体控制流应由确定性代码明确管理。LLM 只应引导控制流的路径，而不应成为控制流本身。这样才能保证可预测性、强健的错误处理，并让开发者为 LLM 的自主性设定清晰边界，防止意外或不良行为。

![拥有自己的控制流](https://apframework.com/static/images/2025-07-08-12-Factor-Agents/180-control-flow.png)

如果你拥有自己的控制流，就能做很多有趣的事情。

可以为特定用例构建专属控制结构。例如，某些工具调用可能需要跳出循环，等待人工或其他长时间任务（如训练管道）响应。你还可以实现：

- 工具调用结果的汇总或缓存
- LLM 结构化输出
- 上下文窗口压缩或其他内存管理
- 日志、追踪和指标
- 客户端速率限制
- 持久睡眠/暂停/“等待事件”

这种模式允许你根据需要中断和恢复代理流程，打造更自然的对话和工作流。

**例如**：我对每个 AI 框架的首要诉求是，必须能在"选择工具"与"调用工具"之间中断代理并稍后恢复。

如果没有这种粒度的可恢复性，就无法在工具调用前进行人工审核或批准，这会导致：

1. 长任务只能暂停在内存中，进程中断就得重头再来
2. 只能让代理处理低风险任务，如研究和总结
3. 让代理做更大更有用的事，但只能祈祷它不会出错

# **理解笔记**

构建 Agent 过程中，使用上下文或者 code 控制流程，LLM 引导控制流的路径，而不是*成为*控制流本身。

- 控制流应由确定性代码主导，LLM 只负责决策建议，避免"黑盒"自动化带来的不可控风险。
- 为关键节点（如工具调用前）设计人工审核或中断机制，提升安全性。
- 将控制流逻辑与 LLM 推理解耦，便于测试和维护。
